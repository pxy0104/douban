# -*- coding: utf-8 -*-# @Time    : 2023/3/4 13:32# @File    : spider_music.py# @Software: PyCharm# @Author  : pxyfrom bs4 import BeautifulSoup  # 网页解析，获取数据import re  # 正则表达式，进行文字匹配import urllib.request, urllib.error  # 指定url，获取网页数据import xlwt  # 进行excel操作import sqlite3  # 进行SQLite数据库操作"""1.爬取网页2.解析数据3.获取数据""""""['https://movie.douban.com/subject/2363506/', 'https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2197897857.jpg', '地球上的星星', 'Taare Zameen Par', '8.9', '199641', '天使保护事件始末', '导演: 阿米尔·汗 Aamir Khan主演: 达席尔·萨法瑞 Darsheel Safary  阿... 2007印度剧情 儿童 家庭']"""# 音乐详情链接findLink = re.compile(r'<a class="nbg" href="(.*)" onclick="moreurl')# 查询图片详情链接findImage = re.compile(r'<i.*src="(.*?)"')"""<a href="https://music.douban.com/subject/1427374/" onclick="moreurl(this,{i:'2',query:'',subject_id:'1427374',from:'music_subject_search'})">华丽的冒险<span style="font-size:12px;">華麗的冒險</span></a>['https://music.douban.com/subject/5360525/', 'https://img2.doubanio.com/view/subject/s/public/s4550552.jpg', '她说', '概念自选辑', '林俊杰 / 2010-12-08 / 专辑 / CD / 流行', '8.3', '35002']"""# 查第一个名字findFirstName = re.compile(r'<a.*>(.*)</a>', re.S)# 查第一个名字(带有第二个名字的)findFirstNameWithSpan = re.compile(r'<a.*>(.*?)<span style="font-size:12px;">.*?</span>', re.S)findSecondName = re.compile(r'<span style="font-size:12px;">(.*?)</span>')# <p class="pl">周杰伦 / 2001-09-14 / 专辑 / CD / 流行</p>findInfo = re.compile(r'<p class="pl">(.*?)</p>')# 评分<span class="rating_nums">9.5</span>findScore = re.compile(r'<span class="rating_nums">(.*)</span>')# 评论人数 findReview  <span class="pl">#     (#             172630人评价#     )# </span>findReview = re.compile(r'<span class="pl">(.*?)人评价.*</span>', re.S)def main():    baseurl = "https://music.douban.com/top250?start="    # baseurl = '.\\douban.html'    datalist = getData(baseurl)    # print(datalist)    # 保存到excel中    path = ".\\musicTop250.xls"    saveData(datalist, path)    # print(len(datalist))    # 将数据存入SQLite    dbpath = ".\\music.db"    saveDateToDB(datalist, dbpath)    print("success")def getData(baseurl):    datalist = []    for i in range(0, 10):        url = baseurl + str(i * 25)        html = askURL(url)  # 分次获取页面内容        # html = open("douban.txt", "r+", encoding="utf-8")        # sss = str(html.read())        # print(sss)        soup = BeautifulSoup(html, "html.parser")        for item in soup.find_all('tr', class_="item"):            data = []  # 保存一首音乐item全部信息            # print(item)            item = str(item)            # 音乐详情链接            link = re.findall(findLink, item)[0]            # print(link)            data.append(link)            # print(data)            # 封面 查找            imgSrc = re.findall(findImage, item)[0]            data.append(imgSrc)            # print(imgSrc)            # 正则查找第一个名字            firstNameWithSpan = re.findall(findFirstNameWithSpan, item)            firstNameWithSpan = str(firstNameWithSpan)            firstNameWithSpan = firstNameWithSpan.replace(r'\n', '')            firstNameWithSpan = re.sub(" ", "", firstNameWithSpan)            # print(firstNameWithSpan)            if len(firstNameWithSpan) > 2:                # firstNameWithSpanList = firstNameWithSpan.split("'")                # print(hasSpanNamelist[1])                firstNameWithSpan = firstNameWithSpan[2:len(firstNameWithSpan)-2]                data.append(firstNameWithSpan)            else:                firstName = re.findall(findFirstName, item)                firstName = str(firstName)                firstName = firstName.replace(r'\n', '')                firstName = re.sub(" ", "", firstName)                # firstName = firstName.split("'")                firstName = firstName[2:len(firstName)-2]                data.append(firstName)            # 正则查找第二个名字            secondName = re.findall(findSecondName, item)            if len(secondName) == 0:                data.append("")            else:                secondName = str(secondName)                # print(secondName)                # print(secondName[2:len(secondName)-2])                # secondName = secondName.split("'")                data.append(secondName[2:len(secondName)-2])            # 测试 第二列 firstName 第三列secondName            # 音乐人介绍            info = re.findall(findInfo, item)[0]            data.append(info)            # print(info)            # print(data)            score = re.findall(findScore, item)[0]            data.append(score)            # print(score)            reviews = re.findall(findReview, item)[0]            reviews = reviews.strip()            reviews = re.sub("\(", "", reviews)            reviews = reviews.strip()            data.append(reviews)            # print(reviews)            datalist.append(data)        print('______')        print(len(datalist))        print('______')            # print(data)    return datalistdef saveData(datalist, path):    book = xlwt.Workbook(encoding="utf-8", style_compression=0)    sheet = book.add_sheet('musicTop250', cell_overwrite_ok=True)    col = ("音乐详情链接", "封面链接", "作品", "作品别名", "介绍", "评分", "评论数")    # print(len(col))    for i in range(0, len(col)):        sheet.write(0, i, col[i])  # 写入列名    # worksheet.write(0,0,'hello')    for i in range(0, len(datalist)):        # print("第 %d 条" % i + 1)        data = datalist[i]        for j in range(0, len(col)):            sheet.write(i + 1, j, data[j])    book.save(path)def init_db(dbpath):    sql = '''            create table music247            (            id integer primary key autoincrement,            info_link text,            imag_link text,            mname varchar,            oname varchar,            bd text,            score numeric,            reviews numeric            )    '''    conn = sqlite3.connect(dbpath)    cursor = conn.cursor()    cursor.execute(sql)    conn.commit()    conn.close()def saveDateToDB(datalist, dbpath):    init_db(dbpath)    conn = sqlite3.connect(dbpath)    cur = conn.cursor()    for data in datalist:        for index in range(len(data)):            data[index] = '"' + str(data[index]) + '"'        sql = '''insert into music247(info_link,imag_link,mname,oname,bd,score,reviews)                    values(%s)''' % ",".join(data)        # print(sql)        cur.execute(sql)        conn.commit()    cur.close()    conn.close()# 尝试获取网页页面def askURL(url):    """    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.57    """    head = {        "User-Agent": "{Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36 Edg/110.0.1587.57}"    }    request = urllib.request.Request(url, headers=head)    html = ""    try:        response = urllib.request.urlopen(request)        html = response.read().decode("utf-8")        # print(html)    except urllib.error.URLError as e:        if hasattr(e, "code"):            print(e.code)        if hasattr(e, "reason"):            print(e.reason)    return htmlif __name__ == "__main__":    # askURL("https://music.douban.com/top250")    main()